{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset, Audio, DatasetInfo, Features, Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load audio files under folder \"sanskrit\" and it's transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_folder(folder):\n",
    "    # folder has multiple audio files .wav (sent_1.wav)and a .txt\n",
    "    # transcriptions.txt file has the transcription of each audio file in a new line\n",
    "\n",
    "    # get all audio files; sorted based on file_number: sent_1.wav, sent_2.wav, sent_3.wav, ...\n",
    "    audio_files = sorted([f for f in os.listdir(folder) if f.endswith(\".wav\")], key=lambda f: int(f.split(\"_\")[1].split(\".\")[0]))\n",
    "    if len(audio_files) == 0:\n",
    "        return None\n",
    "    \n",
    "    # get transcription file\n",
    "    transcription_file = [f for f in os.listdir(folder) if f.endswith(\".txt\")][0]\n",
    "\n",
    "    #join folder and audio file name\n",
    "    audio_files = [os.path.join(folder, audio_file) for audio_file in audio_files]\n",
    "    #join folder and transcription file name\n",
    "    transcription_file = os.path.join(folder, transcription_file)\n",
    "\n",
    "    # read transcription file\n",
    "    transcription_texts = pd.read_csv(transcription_file, sep=\",\", header=None)[1].str.strip().values\n",
    "\n",
    "    audiofile2transcription = {}\n",
    "    # create a dictionary with audio file name as key and transcription as value\n",
    "    for audio_file, transcription_text in zip(audio_files, transcription_texts):\n",
    "        audiofile2transcription[audio_file] = transcription_text\n",
    "\n",
    "    return audiofile2transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do this for all folders in side \"sanskrit\" folder\n",
    "audiofile2transcription = {}\n",
    "ROOT_DIR = \"sanskrit\"\n",
    "RECORDING_FOLDER = os.path.join(ROOT_DIR, \"newsonair_v5\", \"sanskrit\")\n",
    "for folder in os.listdir(RECORDING_FOLDER):\n",
    "    folder = os.path.join(RECORDING_FOLDER, folder)\n",
    "    more_data = search_folder(folder)\n",
    "    if more_data is not None:\n",
    "        audiofile2transcription.update(more_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_for_dataset = {\n",
    "    \"audio\": list(audiofile2transcription.keys()),\n",
    "    \"transcriptions\": list(audiofile2transcription.values())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_san = Dataset.from_dict(dict_for_dataset).cast_column(\"audio\", Audio(sampling_rate=16_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': 'sanskrit\\\\newsonair_v5\\\\sanskrit\\\\NSD-Sanskrit-Sanskrit-0655-0700-2019101072720\\\\sent_1.wav',\n",
       " 'array': array([-0.00112915, -0.00106812, -0.00100708, ..., -0.00848389,\n",
       "        -0.01177979, -0.00576782]),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_san[0][\"audio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_san_info = DatasetInfo(\n",
    "    description=\"Shrutilipi is a labelled ASR corpus for Sanskrit\",\n",
    "    features=Features({\"audio\": Audio(), \"transcriptions\": Value(\"string\")}),\n",
    "    supervised_keys=None,\n",
    "    homepage=\"https://ai4bharat.org/shrutilipi\",\n",
    "    citation=\"\"\"\n",
    "        @misc{https://doi.org/10.48550/arxiv.2208.12666,\n",
    "            doi = {10.48550/ARXIV.2208.12666},\n",
    "            url = {https://arxiv.org/abs/2208.12666},\n",
    "            author = {Bhogale, Kaushal Santosh and Raman, Abhigyan and Javed, Tahir and Doddapaneni, Sumanth and Kunchukuttan, Anoop and Kumar, Pratyush and Khapra, Mitesh M.},\n",
    "            title = {Effectiveness of Mining Audio and Text Pairs from Public Data for Improving ASR Systems for Low-Resource Languages},\n",
    "            publisher = {arXiv},\n",
    "            year = {2022},\n",
    "            copyright = {arXiv.org perpetual, non-exclusive license}\n",
    "        }\n",
    "    \"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9562f3ad5a64e2cab4053de18b380ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/16 shards):   0%|          | 0/14414 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# not sure if this inplace operation is correct; but seem to work\n",
    "dataset_san._info = dataset_san_info\n",
    "dataset_san._num_rows = len(dict_for_dataset)\n",
    "dataset_san.save_to_disk(\"shrutilipi_sanskrit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f33a4cc18949ebac9ec13a473caa0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/901 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca006b345e14ce794db448baf6b75b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef66457578594d0fbb4c0797d426b579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2eaffe292244480bdea56bf634a3dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TOKEN = \"API_KEY\"\n",
    "dataset_san.push_to_hub(\"shrutilipi_sanskrit\", token=TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
